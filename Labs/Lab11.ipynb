{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erdos-Renyi-model\n",
    "\n",
    "The Erdos-Renyi-model is constructed as follows:\n",
    "\n",
    "- We are given $n$ nodes and a link probability $p$, that can be constant or dependent on $n$. \n",
    "- For each pair of nodes $\\{i,j\\}$ we add the (unweighted) link $\\{i,j\\}$ with independent probability $p$. \n",
    "\n",
    "**Expected number of (undirected) links**: $\\binom{n}{2}p = n(n-1)p/2$.\n",
    "\n",
    "**Expected average degree**: $E[\\overline{w}] = (n-1)p$.\n",
    "\n",
    "We now generate an Erdos-Renyi graph and investigate its properties, specifically **connectedness** and **degree distribution**.\n",
    "\n",
    "### Case 1: constant $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Construction of the Erdos-Renyi model\n",
    "\n",
    "p = 0.1\n",
    "n = 20\n",
    "W = np.zeros((n,n))\n",
    "\n",
    "# fill the bottom-left block of W\n",
    "for i in range(n):\n",
    "    for j in range(i):\n",
    "        W[i,j] = np.random.choice([0,1], p=[1-p,p])\n",
    "\n",
    "# fill the top-right block\n",
    "W = W + W.T\n",
    "    \n",
    "G = nx.from_numpy_array(W)\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters, the graph is disconnected with high probability, bacause the expected average degree is small. Let us increase $n$ while keeping $p$ constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "n = 200\n",
    "W = np.zeros((n,n))\n",
    "W = W + W.T\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i):\n",
    "        W[i,j] = np.random.choice([0,1], p= [1-p,p])\n",
    "    \n",
    "G = nx.from_numpy_array(W, create_using=nx.Graph)\n",
    "\n",
    "nx.draw(G)\n",
    "\n",
    "print(\"Expected number of links:\", p*n*(n-1)/2)\n",
    "print(\"Number of links:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The graph is connected:\", nx.is_connected(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the plot of the graph is confusing, but the graph is connected.\n",
    "\n",
    "This shows that $p$ is not the best parameter to capture the connectivity properties of an Erdos-Renyi graph, unless we specify $n$. In the next part, we shall consider cases in which $p$ is a function of $n$.\n",
    "\n",
    "The problem of keeping $p$ fixed is that the expected average degree grows linearly with $n$, which is quite unrealistic. In fact, typically real networks are sparse.\n",
    "\n",
    "We study two regimes of interest: \n",
    "- $p \\propto log(n)/n$ (average degree scaling with $log(n)$), and \n",
    "- $p \\propto 1/n$ (constant average degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: $p = a \\frac{log(n)}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate a large network and count the number of isolated nodes as a first connectivity measure. As we have seen before, if $p$ is fixed and $n$ increases the connectivity of the graph increases. Let us see if this changes when $p$ scales with $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "n = 100\n",
    "p = a*np.log(n)/n\n",
    "\n",
    "W = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i):\n",
    "        W[i,j] = np.random.choice([0,1], p= [1-p,p])\n",
    "        \n",
    "W = W + W.T\n",
    "degree = W @ np.ones(n)\n",
    "\n",
    "nodes_zero_degree = len(degree[degree == 0.])\n",
    "\n",
    "print(\"Number of isolated nodes:\", nodes_zero_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us increase $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "n_vec = np.arange(100,1100,200)\n",
    "\n",
    "for n in n_vec:\n",
    "    \n",
    "    p = a*np.log(n)/n\n",
    "    W = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            W[i,j] = np.random.choice([0,1], p= [1-p,p])\n",
    "\n",
    "    W = W + W.T\n",
    "    degree = W @ np.ones(n)\n",
    "    \n",
    "    nodes_zero_degree = len(degree[degree == 0.])\n",
    "    \n",
    "    print(\"n:\", n)\n",
    "    print(\"Number of isolated nodes:\", nodes_zero_degree, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try different values of $a$ while keeping $n$ fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vec = np.arange(0.55,1.45,0.1)\n",
    "\n",
    "nodes_zero_degree = []\n",
    "\n",
    "for a in a_vec:\n",
    "    n = 600\n",
    "    p = a*np.log(n)/n\n",
    "\n",
    "    W = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            W[i,j] = np.random.choice([0,1], p=[1-p,p])\n",
    "\n",
    "    W = W + W.T\n",
    "    degree = W @ np.ones(n)\n",
    "\n",
    "    nodes_zero_degree.append(len(degree[degree == 0.]))\n",
    "    \n",
    "plt.plot(list(a_vec), nodes_zero_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, as $a$ increases the connectivity of the graph increases and the number of isolated nodes decreases.\n",
    "\n",
    "In fact, one can prove that a phase transition occurs as $a$ varies.\n",
    "\n",
    "The probability that a node is isolated is $(1-p)^{n-1}$. Thus, the number of isolated nodes in expectation is\n",
    "\n",
    "$$\n",
    "E[N_0] = \\sum_{i} (1-p)^{n-1} = n(1-p)^{n-1}.\n",
    "$$\n",
    "\n",
    "If $p$ is a constant, as $n \\to +\\infty$ we get $E[N_0] \\to 0$.\n",
    "\n",
    "Instead one can show that if $p = a \\frac{log(n)}{n}$, then $E[N_0] \\to n^{1-a}$ as $n \\to +\\infty$, which means that:\n",
    "\n",
    "- if $a > 1$, $E[N_0] = 0$;\n",
    "- if $a < 1$, $E[N_0] = +\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of isolated nodes is a measure of connectivity of the graph. Another interesting question is whether the graph is connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vec = np.arange(0.45,1.55,0.1)\n",
    "\n",
    "is_connected = []\n",
    "\n",
    "for a in a_vec:\n",
    "    # generate the random graph\n",
    "    n = 600\n",
    "    p = a*np.log(n)/n\n",
    "\n",
    "    W = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            W[i,j] = np.random.choice([0,1], p= [1-p,p])\n",
    "\n",
    "    W = W + W.T\n",
    "    G = nx.from_numpy_array(W, create_using=nx.Graph)\n",
    "    # check whether is connected or not\n",
    "    is_connected.append(nx.is_connected(G))\n",
    "    \n",
    "plt.plot(list(a_vec), is_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can prove that, as $n \\to +\\infty$, with large probability:\n",
    "- if $a>1$, the graph is connected;\n",
    "- if $a<1$, the graph is not connected.\n",
    "\n",
    "It can also be proven that the diameter of the graph scales with $log(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: $p = \\frac{\\lambda}{n}$.\n",
    "\n",
    "While in case of constant $p$ and $p \\propto \\frac{log(n)}{n}$ the average degree of the nodes diverges as $n$ grows, here the average degree remains bounded. One can show that the degree distribution follows a Poisson distribution, i.e.,\n",
    "\n",
    "$$\n",
    "p_k := \\frac{1}{n}|\\{i: w_i = k\\}| = e^{-\\lambda}\\frac{\\lambda^k}{k!}\n",
    "$$\n",
    "\n",
    "In this case the graph is with probability 1 disconnected as $n \\to +\\infty$. Still, there is another phase transition occurring regarding the size of the largest connected component. Specifically, as $n \\to +\\infty$:\n",
    "\n",
    "- if $\\lambda<1$, then the size of each connected component i satisfies with probability 1 $C_i \\le A log(n)$, i.e., each connected component contains a vanishing fraction of the total number of ndoes;\n",
    "- if $\\lambda>1$, with probability one the largest component has size $C_{max} = n(1-x)$, where $x$ solves $x = e^{\\lambda(x-1)}$. Moreover, the size of the second largest component scales with $log(n)$.\n",
    "\n",
    "The last property is proved by showing that an Erdos-Renyi graph is locally tree-like (i.e., there are no short cycles) and using results from branching processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "\n",
    "a = 4\n",
    "n = 1000\n",
    "p = a/n\n",
    "\n",
    "W = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i):\n",
    "        W[i,j] = np.random.choice([0,1], p= [1-p,p])\n",
    "\n",
    "W = W + W.T\n",
    "G = nx.from_numpy_array(W, create_using=nx.Graph)\n",
    "\n",
    "degree = W @ np.ones(n)\n",
    "degreeCount = collections.Counter(degree)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.bar(deg, cnt, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Degree ER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the degree distribution is first increasing and then decreasing, meaning that a large fraction of the nodes has a degree close to the expected average degree, thus the average degree is a good approximation for the degree of a random node of the graph. The variance of the degree distribution is \"small\".\n",
    "\n",
    "We shall see in the next lecture that in real networks, as well as other random graphs (e.g., preferential attachment), the variance of the degree distribution is large, i.e., there are a few nodes with very large degree and many nodes with a small degree (compared to average degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally compute the **clustering coefficient** of the graph, which is the number of triangles in the graph.\n",
    "\n",
    "In terms of social networks, clustering coefficient in some sense describes \"how many friends of a given node are friends to each other\".\n",
    "\n",
    "We expect that clustering coefficient in ER graph is small. Indeed, because of the random structure of the connections there is no reason to expect triangles in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_ER = nx.average_clustering(G)\n",
    "\n",
    "print(\"Clustering coefficient in ER graph:\", clustering_ER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small world networks\n",
    "\n",
    "Small world networks are characterized by two features:\n",
    "\n",
    "- small diameter (sublinear in $n$);\n",
    "- large clustering coefficient (i.e., large number of triangles in the graph).\n",
    "\n",
    "For the range of parameters $(n,p)$ that make the graph connected, ER graphs satisfy the first condition (the diameter scales with $log(n)$), but not the second one.\n",
    "\n",
    "Let us see how to generate a small world network. An example is as follows. We start with the following augmented ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 12\n",
    "\n",
    "G = nx.cycle_graph(n_nodes)\n",
    "\n",
    "for n in range(n_nodes):\n",
    "    G.add_edge(n,((n+2) % n_nodes))\n",
    "    G.add_edge(n,((n-2) % n_nodes))\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "nx.draw(G,pos,with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate larger graphs like this, and investigate clustering coefficient and diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_vec = [40,80,160,320,640]\n",
    "\n",
    "for n_nodes in n_nodes_vec:\n",
    "    G = nx.cycle_graph(n_nodes)\n",
    "\n",
    "    for n in range(n_nodes):\n",
    "        G.add_edge(n,((n+2) % n_nodes))\n",
    "        G.add_edge(n,((n-2) % n_nodes))\n",
    "\n",
    "    print(\"n:\", n_nodes)\n",
    "    print(\"diameter\", nx.diameter(G))\n",
    "    print(\"clustering coefficient\", nx.average_clustering(G), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two observations:\n",
    "- the clustering coefficient is large and does not scale with $n$;\n",
    "- the diameter scales linearly with $n$.\n",
    "\n",
    "To reduce the diameter and obtain a small world network, it is sufficient to add some random long-distance connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.002\n",
    "n_nodes = 640\n",
    "\n",
    "G = nx.cycle_graph(n_nodes)\n",
    "\n",
    "for n in range(n_nodes):\n",
    "    G.add_edge(n,((n+2) % n_nodes))\n",
    "    G.add_edge(n,((n-2) % n_nodes))\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    for j in range(n_nodes):\n",
    "        if np.random.rand() < p:\n",
    "            G.add_edge(i,j)\n",
    "            \n",
    "print(\"Diameter:\", nx.diameter(G))\n",
    "print(\"Clustering coefficient\", nx.average_clustering(G), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new graph has a small diameter. The clustering coefficient is reduced, but still much larger than in Erdos-Renyi graph.\n",
    "\n",
    "Still, the degree distribution is a shifted Poisson distribution, which differs from the most of the real networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "In the first part of the lecture we have introduced and analysed the properties of two families of random graphs:\n",
    "- (undirected) **Erdos-Renyi** graph, which is a graph whose links are uniformly random;\n",
    "- **small world** graphs, in which there is a large fraction of short range links plus a small fraction of random long range links.\n",
    "\n",
    "Specifically:\n",
    "- we have shown that both in the Erdos-Renyi and in the small world graphs the **diameter** scales sublinearly with $n$ (specifically, with $log(n)$);\n",
    "- we have seen that the **degree distribution** of the graphs (for ER this holds $p \\propto 1/n$ if is Poisson-like), i.e., it has small variance.\n",
    "- we have compared the **clustering coefficient** of the two models, i.e., the number of triangles in the graph, showing that in Erdos-Renyi graph the clustering coefficient is much smaller than in the small world graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we consider a real citation network, and compare how well the random graphs approximate the citation network.\n",
    "By doing so, we introduce the **preferential attachment model** and the **configuration model** and complete our analysis on random graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferential attachment model\n",
    "\n",
    "This is a model of growing graph. The idea is the following (we consider the undirected case):\n",
    "\n",
    "- we start at time $t=0$ with an initial undirected graph $\\mathcal{G}_0$;\n",
    "- at each time $t \\in \\{1,2,...\\}$, we create a new graph $\\mathcal{G}_t$ obtained by adding a new node to $\\mathcal{G}_{t-1}$, and connecting such a node to $c$ nodes randomly selected. \n",
    "\n",
    "If the nodes are selected with uniform probability, we call the model **uniform attachment model**. The more interesting case is when the nodes are selected with a probability which depends on the degree of the nodes, which is called **preferential attachment model**. Several models of preferential attachment may be defined.\n",
    "\n",
    "In the model introduced by **Price**, the probability for a new node introduced at time $t$ of attaching to a node $i$ is proportional to $a + w_i(t-1)$, where $a > -1$, and $w_i(t-1)$ indicates the degree of node $i$ at time $t-1$.\n",
    "\n",
    "In the particular case $a=0$ the model is known as **Barabasi-Albert** model.\n",
    "\n",
    "### Degree distribution of a preferential attachment model\n",
    "It can be proven that, as $n \\to +\\infty$, the degree distribution of the Barabasi-Albert model ($a=0$), if each new node attachs to $c$ nodes, follows a power-law distribution, specifically,\n",
    "\n",
    "$$\n",
    "p_k =\n",
    "\\begin{cases}\n",
    "0 \\quad &\\text{if} \\ k<c\\\\\n",
    "\\frac{2}{2+c} &\\text{if} \\ k=c\\\\\n",
    "\\frac{2c(c+1)}{k(k+1)(k+2)} &\\text{if} \\ k>c.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Asymptotically for large $k$, this means that $p_k \\propto k^{-3}$, which is a power law with exponential $\\gamma=3$.\n",
    "\n",
    "For the more general Price model, it can be proven that for large $k$, $p_k \\propto k^{-(3+a)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generalizations of preferential attachment model**: \n",
    "- this model can be generalized to the case of directed networks, by assuming that the probability of connecting to a node $i$ depends on its indegree $w_i^-$;\n",
    "- the model can be also generalized by assuming that the number of outlinks of each node is a random variable. This allows to obtain different out-degree distribution (otherwise in directed model all the nodes would have the same out-degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will study other properties of preferential attachment model (e.g., the diameter) in the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random graphs as a model for a citation network\n",
    "The real world network in this problem is a citation network with 10000 papers. It can be loaded with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = sio.loadmat('citation1.mat', variable_names=['citation'])\n",
    "citation = citation['citation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a directed network where each node represents a paper and a link from node i to j means that paper i cited paper j. The variable `citation` is an array with 3 columns. Each row contains the tail and head node of a link and the weight associated to such link in the adjacency matrix of the graph (in this case, the weight is either 1 or 0). The graph is constructed from the `citation` variable as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i,j,w in citation:\n",
    "    if w != 0:\n",
    "        G.add_edge(i,j)\n",
    "\n",
    "n_nodes_cit = nx.number_of_nodes(G)\n",
    "n_links_cit = nx.number_of_edges(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we analyze how to approximate the citation graph with different random graph models. We then compare the obtained approximations to see which one is the best for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erdos-Renyi-model\n",
    "To approximate the citation network we construct an Erdos-Renyi-model with as many nodes as the real network, that is $n$. Remember that the expected number of links in Erdos-Renyi undirected graphs is $\\binom{n}{2}p$ where $p$ is the probability of there being a link between any two distinct nodes i and j. We choose $p$ such that the expected number of links is the same as the number of links in the actual citation network. By construction, this random graph will not have any self loop.\n",
    "\n",
    "**Remark**: we here construct a directed Erdos-Renyi graph, since the citation graph is directed. The generalization is straightforward: instead of adding undirected links $\\{i,j\\}$ with probability $p$, here we add a directed link $(i,j)$ with probability $p$. Thus, the average in-degree and out-degree are both $(n-1)p$, and the expected number of links is $n(n-1)p=2\\binom{n}{2}p$, where $\\binom{n}{2}p$ is the expected number of undirected links in the undirected Erdos-Renyi graph with $n$ nodes and link probability $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of the Erdos-Renyi model\n",
    "\n",
    "# choose p so that the expected number of links is the same as n_links_cit\n",
    "# factor 2 at denominator is because G is directed\n",
    "p = n_links_cit/(sp.special.binom(n_nodes_cit,2) * 2) \n",
    "# add links between couple of different nodes with probability p\n",
    "WER = np.random.choice([0,1], size=(n_nodes_cit, n_nodes_cit), p= [1-p,p])\n",
    "# GER has no self loops\n",
    "for n in range(n_nodes_cit):\n",
    "    WER[n,n] = 0\n",
    "    \n",
    "GER = nx.from_numpy_array(WER, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The configuration model \n",
    "Here we construct a configuration model to approximate the citation network. To do this, we proceed as follows: given the in and out-degree of the real network, we pick uniformly at random one out-link and one in-link and connect them.\n",
    "\n",
    "In this model, we are able to reproduce the exact in-degree and out-degree distribution.\n",
    "\n",
    "Instead, in the ER graph, we imposed that the average degree is the same as in the citation graph, but the resulting degree distribution is approximately a Poisson distribution independently of the original degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of the Configuration model\n",
    "WCM = np.zeros((n_nodes_cit, n_nodes_cit))\n",
    "# G.out_degree() is a list of tuples in the form (node,degree)\n",
    "# we select degree and append to array of degrees\n",
    "residual_out_degree = np.array(list(degree for node, degree in G.out_degree()))\n",
    "\n",
    "# same for the indegree\n",
    "residual_in_degree = np.array(list(degree for node, degree in G.in_degree()))\n",
    "\n",
    "print(residual_out_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each node\n",
    "for i in range(n_nodes_cit):\n",
    "    # while there are unconnected out \"half links\" starting from the node\n",
    "    while residual_out_degree[i] > 0:\n",
    "        available_targets = np.arange(n_nodes_cit)\n",
    "        # randomly connect the half link to node j, so that the link is (i,j)\n",
    "        # the probability of connecting to j is proportional to the residual_indegree of j\n",
    "        target = np.random.choice(available_targets, p = residual_in_degree/sum(residual_in_degree))\n",
    "        WCM[i,target] = 1\n",
    "        # decrease out/in degree of the connected nodes\n",
    "        residual_in_degree[target] -=1\n",
    "        residual_out_degree[i] -=1\n",
    "\n",
    "GCM = nx.from_numpy_array(WCM, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferential attachment model\n",
    "The preferential attachment is a model for growing random graphs which was explicitly introduced to model citation networks. We now explore this model to see if it is capable of approximating the real citation network.\n",
    "\n",
    "We generate a random graph by the preferential attachment model, so that the final number of nodes n is the same as in the real citation network and so that the degree distrubution is similar. To do this, we start with directed graph $G_0$ containing 2  nodes connected to each other.\n",
    "\n",
    "At timestep $t$ $(t\\geq1)$, we add a new node to the graph and connect it to $c$ other nodes already present in $G_{t}$, the resulting graph is called $G_{t+1}$. \n",
    "\n",
    "The value of $c$ is chosen randomly with probabilities according to the out-degree distribution of the real citation network, so that we obtain the correct out-degree distribution. \n",
    "\n",
    "For each of the $c$ new connections, the destination node is chosen with probability proportional to the in-degree distribution of $G_{t}$ plus a constant $a$ , so that the probability that node $i$ is chosen is given by\n",
    "\n",
    "$$\n",
    "p_i(t)=\\frac{w_i^-(t) + a}{\\sum_j (w_j^-(t)+a)}.\n",
    "$$\n",
    "\n",
    "**Remark**: when $a \\neq 0$, each node has an intrinsic probability of being selected as a neighbor from new nodes, regardless of its in-degree. Observe that each node enters in the network with in-degree $0$. Thus, in the directed Price model $a > 0$, otherwise none of the nodes added at time $t \\ge 1$ cannot be chosen by new nodes and cannot increase their indegree.\n",
    "\n",
    "The process stops when the total number of nodes $n$ is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferential attachment\n",
    "GPA = nx.DiGraph()\n",
    "# GPA is initialized to G0, containing two nodes connected to each other\n",
    "GPA.add_edges_from([(0,1),(1,0)])\n",
    "\n",
    "# compute out degree distribution of real citation graph\n",
    "\n",
    "# degree sequence contains the out degree of nodes ordered from larger to smaller\n",
    "degree_sequence = sorted([d for n, d in G.out_degree()], reverse=True) \n",
    "# count for each out-degree value, how many nodes have that out-degree\n",
    "# degreeCount is a list of tuples (degree value, number of nodes)\n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "# zip() returns an iterator of tuples where the first item in each passed tuple \n",
    "# is paired together, the second item in each passed tuple are paired together\n",
    "# and so on.\n",
    "# In this way we obtain deg, which is the tuple of degree values, and\n",
    "# cnt which is the tuple of the counts.\n",
    "\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "deg_distr = np.array(cnt)/sum(cnt)\n",
    "\n",
    "print(\"Degree values in the network:\", deg)\n",
    "print(\"Counter for each degree\", cnt)\n",
    "print(\"Degree frequency\", deg_distr)\n",
    "\n",
    "# set a, the intrinsic probability of a node to be selected as a neighbor \n",
    "# from new nodes\n",
    "a = 2\n",
    "\n",
    "# add the remaining nodes one at a time\n",
    "for node in range(2,n_nodes_cit):\n",
    "    # compute degree of new node according to deg_distr (degree distribution\n",
    "    # of the real citation graph).\n",
    "    # the min guarantees that the new node is not assigned a degree\n",
    "    # larger than the current size of the preferential attachment graph\n",
    "    degree = min(np.random.choice(deg,p=deg_distr), len(GPA)) \n",
    "    # choose `degree` neighbors for node to connect to according to their \n",
    "    # in-degree in the current approximation GPA.\n",
    "    # compute updated in degree sequence\n",
    "    in_deg_PA = [d for n, d in GPA.in_degree()] \n",
    "    # add a so that also node with 0 in-degree have non-zero probability\n",
    "    # of being chosen\n",
    "    in_deg_PA = np.array(in_deg_PA)+a \n",
    "    # normalize to obtain a probability distribution\n",
    "    in_deg_PA = in_deg_PA/sum(in_deg_PA)\n",
    "    # replace=False guarantees no neighbor is chosen twice\n",
    "    neighbors = np.random.choice(np.arange(len(GPA)), p=in_deg_PA, size=degree, replace=False)\n",
    "    # add the new node (new node is added even if its out-degree is zero)\n",
    "    GPA.add_node(node)\n",
    "    # add the new links \n",
    "    for neigh in neighbors:\n",
    "        GPA.add_edge(node,neigh) \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models\n",
    "We use the following measures to investigate how the Erdos-Renyi-model, Configuration Model and Preferntial Attachment model are able to approximate the real citation network.\n",
    "1. Diameter \n",
    "2. Average distance between nodes\n",
    "3. Degree distribution\n",
    "\n",
    "**Remark:** since the network is not strongly connected, with the usual computation the Diameter becomes infinity. To get a more meaningful result, one can get this diameter as the maximum diameter of each connected component. A similar argument applies to the average distance between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Diameter\n",
    "length_dict = dict(nx.all_pairs_shortest_path_length(G))\n",
    "lengths = [lenght for d in length_dict.values() for lenght in d.values()]\n",
    "diameter = max(lengths)\n",
    "print(\"Diameter:\", diameter)\n",
    "\n",
    "length_dict_ER = dict(nx.all_pairs_shortest_path_length(GER))\n",
    "lengths_ER = [lenght for d in length_dict_ER.values() for lenght in d.values()]\n",
    "diameter_ER = max(lengths_ER)\n",
    "print(\"Diameter ER:\", diameter_ER)\n",
    "\n",
    "length_dict_CM = dict(nx.all_pairs_shortest_path_length(GCM))\n",
    "lengths_CM = [lenght for d in length_dict_CM.values() for lenght in d.values()]\n",
    "diameter_CM = max(lengths_CM)\n",
    "print(\"Diameter CM:\", diameter_CM)\n",
    "\n",
    "length_dict_PA = dict(nx.all_pairs_shortest_path_length(GPA))\n",
    "lengths_PA = [lenght for d in length_dict_PA.values() for lenght in d.values()]\n",
    "diameter_PA = max(lengths_PA)\n",
    "print(\"Diameter PA:\", diameter_PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average distance\n",
    "\n",
    "ad = np.average(lengths)\n",
    "print(\"Average distance:\",ad)\n",
    "ad_ER = np.average(lengths_ER)\n",
    "print(\"Average distance ER:\",ad_ER)\n",
    "ad_CM = np.average(lengths_CM)\n",
    "print(\"Average distance CM:\",ad_CM)\n",
    "ad_PA = np.average(lengths_PA)\n",
    "print(\"Average distance PA:\",ad_PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-degree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "degree_sequence = sorted([d for n, d in G.out_degree()], reverse=True) \n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "degree_sequence_ER = sorted([d for n, d in GER.out_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_ER = collections.Counter(degree_sequence_ER)\n",
    "deg_ER, cnt_ER = zip(*degreeCount_ER.items())\n",
    "\n",
    "degree_sequence_CM = sorted([d for n, d in GCM.out_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_CM = collections.Counter(degree_sequence_CM)\n",
    "deg_CM, cnt_CM = zip(*degreeCount_CM.items())\n",
    "\n",
    "degree_sequence_PA = sorted([d for n, d in GPA.out_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_PA = collections.Counter(degree_sequence_PA)\n",
    "deg_PA, cnt_PA = zip(*degreeCount_PA.items())\n",
    "\n",
    "plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "plt.bar(deg, cnt, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Out Degree\")\n",
    "ax.set_xticks([d + 0.4 for d in deg])\n",
    "ax.set_xticklabels(deg);\n",
    "\n",
    "ax = plt.subplot(2,2,2)\n",
    "plt.bar(deg_ER, cnt_ER, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Out Degree ER\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_ER])\n",
    "ax.set_xticklabels(deg_ER);\n",
    "\n",
    "ax = plt.subplot(2,2,3)\n",
    "plt.bar(deg_CM, cnt_CM, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Out Degree CM\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_CM])\n",
    "ax.set_xticklabels(deg_CM);\n",
    "\n",
    "ax = plt.subplot(2,2,4)\n",
    "plt.bar(deg_PA, cnt_PA, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Out Degree PA\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_PA])\n",
    "ax.set_xticklabels(deg_PA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: Degrees of the real network and of the CM approximation coincide, since the CM model is such that the resulting graph has a prescribed degree distribution. Also the out-degree of the PA model is quite similar, because the out-degree of every node is sampled according to the real out-degree probability distribution. Instead, for the ER the out-degree distribution is Poisson-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-degree\n",
    "\n",
    "degree_sequence = sorted([d for n, d in G.in_degree()], reverse=True)  # degree sequence\n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "degree_sequence_ER = sorted([d for n, d in GER.in_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_ER = collections.Counter(degree_sequence_ER)\n",
    "deg_ER, cnt_ER = zip(*degreeCount_ER.items())\n",
    "\n",
    "degree_sequence_CM = sorted([d for n, d in GCM.in_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_CM = collections.Counter(degree_sequence_CM)\n",
    "deg_CM, cnt_CM = zip(*degreeCount_CM.items())\n",
    "\n",
    "degree_sequence_PA = sorted([d for n, d in GPA.in_degree()], reverse=True)  # degree sequence\n",
    "degreeCount_PA = collections.Counter(degree_sequence_PA)\n",
    "deg_PA, cnt_PA = zip(*degreeCount_PA.items())\n",
    "\n",
    "plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "plt.bar(deg, cnt, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"In Degree\")\n",
    "ax.set_xticks([d + 0.4 for d in deg])\n",
    "ax.set_xticklabels(deg);\n",
    "\n",
    "ax = plt.subplot(2,2,2)\n",
    "plt.bar(deg_ER, cnt_ER, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"In Degree ER\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_ER])\n",
    "ax.set_xticklabels(deg_ER);\n",
    "\n",
    "ax = plt.subplot(2,2,3)\n",
    "plt.bar(deg_CM, cnt_CM, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"In Degree CM\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_CM])\n",
    "ax.set_xticklabels(deg_CM);\n",
    "\n",
    "ax = plt.subplot(2,2,4)\n",
    "plt.bar(deg_PA, cnt_PA, width=0.80, color=\"b\")\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"In Degree PA\")\n",
    "ax.set_xticks([d + 0.4 for d in deg_PA])\n",
    "ax.set_xticklabels(deg_PA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Try to tune the parameters in the PA model (the intrinsic probability of a node to be selected as a neighbor from new nodes, regardless of its in-degree) to obtain a better approximation of the real in-degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "clustering = nx.average_clustering(G)\n",
    "print(\"Clustering coefficient of the graph:\", clustering)\n",
    "\n",
    "clustering_ER = nx.average_clustering(GER)\n",
    "print(\"Clustering coefficient of the ER:\", clustering_ER)\n",
    "\n",
    "clustering_CM = nx.average_clustering(GCM)\n",
    "print(\"Clustering coefficient of the CM:\", clustering_CM)\n",
    "\n",
    "clustering_PA = nx.average_clustering(GPA)\n",
    "print(\"Clustering coefficient of the PA:\", clustering_PA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering coefficient of the PA model is larger than ER or CM, but still much smaller than the real network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The results give an experimental verification of how the preferential attachment model is best suited to approximate citation networks. Indeed, it reaches the best approximation results with respect to all the analyzed measures (for the degree distributions the previous remarks hold)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
