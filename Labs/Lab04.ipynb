{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "- Ford-Fulkerson algorithm\n",
    "- A few remarks on toll in traffic applications\n",
    "- Averaging dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to max-flow problems: Ford-Fulkerson algorithm\n",
    "\n",
    "It is given a graph $G = (V, E)$ which represents a flow network, and two vertices source $s$ and sink $t$ in it. Every edge $(u,v)$ has a capacity $c(u,v)$. We want to find the maximum possible flow from $s$ to $t$ with the following constraints.\n",
    "\n",
    "The desired flow $f$ is constructed iteratively starting from a zero-flow vector: at each round of the algorithm $f$ is updated in such a way that the capacity and balance constraints are not violated.\n",
    "\n",
    "To do this, at each round, given the current flow vector $f$, we define the **residual network** $G_{f}(V,E_{f})$ to be the network with capacity $c_{f}(u,v)=c(u,v)-f(u,v)$. A search on the residual graph $G_f$ is performed to find an **augmenting path** (i.e., a path on the residual network with positive capacity on every edge of the path). If an augmenting path is found, this means that the current flow $f$ on that path can be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm \n",
    "**Inputs**: a graph $G=(V,E)$, a vector of flow capacities $c = (c(u,v))_{(u,v) \\in E}$, a source node $s$, and a sink node $t$\n",
    "\n",
    "**Output**: a flow $f = (f(u,v))_{(u,v) \\in E}$ from $s$ to $t$ of maximum throughput\n",
    "\n",
    "1. $f(u,v)\\leftarrow 0$ for all edges $(u,v)$\n",
    "2. While there is a path $p$ from $s$ to $t$ in $G_{f}$, such that $c_{f}(u,v)=c(u,v)-f(u,v)>0$ for all edges $(u,v)\\in p$:\n",
    " 1. Find $c_{f}(p)=\\min\\{c_{f}(u,v):(u,v)\\in p\\}$\n",
    " 2. For each edge $(u,v)\\in p:$\n",
    "      1. $f(u,v)\\leftarrow f(u,v)+c_{f}(p)$ (Increase the flow along the path)\n",
    "      2. $f(v,u)\\leftarrow f(v,u)-c_{f}(p)$ (Impose the symmetry of the flow)\n",
    "\n",
    "Ford-Fulkerson Algorithm does not specify how to select paths, this is arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: iterative Ford-Fulkerson by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(1,3),(2,3)])\n",
    "\n",
    "pos = {0: (40, 20), 1: (60, 35), 2: (60, 5), 3: (80, 20)}\n",
    "\n",
    "labels = ['0/1000','0/1000','0/1','0/1000','0/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the augmenting path 0-1-3, with residual capacity equal to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','0/1000','0/1','1000/1000','0/1000']\n",
    "\n",
    "colors = ['red','black','black','red','black']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now only an augmenting path, which is 0-2-3, with residual capacity equal to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','1000/1000','0/1','1000/1000','1000/1000']\n",
    "\n",
    "colors = ['black','red','black','black','red']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edmonds-Karp Algorithm\n",
    "The Edmonds–Karp algorithm is an implementation of Ford–Fulkerson where the search order to find augmenting paths is defined. A shortest path that has available capacity is found by a breadth-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "# This class represents a directed graph using adjacency matrix representation\n",
    "class Graph:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue\n",
    "        # We start by visiting the source\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            u = queue.popleft()\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # Augment the flow while there is a path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are no augmenting paths from s to t\n",
    "            # now parent stores the augmenting path found by bfs\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph(W)\n",
    "\n",
    "max_flow, flow = Graph.edmonds_karp(G,0,3)\n",
    "\n",
    "print(\"The maximum flow:\", max_flow, \"\\n\")\n",
    "print(\"The flow distribution: \\n\", flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the steps of the algorithm by adding some print in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_print:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue for BFS\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue.\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            print(\"Queue:\", queue, \"\\n\")\n",
    "            u = queue.popleft()\n",
    "            print(\"Extracted node:\", u, \"\\n\")\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "            \n",
    "            print(\"Parents\", parent, \"\\n\")\n",
    "            print(\"Visited\", visited, \"\\n \\n \\n\")\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        n_iter = 1\n",
    "        print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        # If parent[j] == -1, node 'j' has not been visited yet\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # Augment the flow while there is a path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are no augmenting paths from s to t\n",
    "            # now parent stores the augmenting path found by bfs\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            n_iter += 1\n",
    "            print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph_print(W)\n",
    "\n",
    "max_flow, flow = Graph_print.edmonds_karp(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx implements the Edmonds-Karp algorithm. \n",
    "\n",
    "The `networkx.algorithms.flow.edmonds_karp` function returns the residual network resulting after computing the maximum flow.\n",
    "\n",
    "Networkx also provides the functions `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut` which compute the maximun throughput and  the value and the node partition of a minimum cut, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to traffic application: system optimum vs Wardrop equilibria\n",
    "\n",
    "We have seen an example on this network, with throughput 1.\n",
    "\n",
    "![figure](pigou.png)\n",
    "\n",
    "Optimal flow is the feasible flow $f^*$ that minimizes $\\sum_e \\psi_e(f_e)$, (typically, $\\psi_e(f_e) = f_e d_e(f_e)$)\n",
    "\n",
    "Wardrop equilibrium is a flow such that no users have incentive in modifying their path.\n",
    "\n",
    "Optimal flow (with respect to standard cost functions) is $f^* = (1/2, 1/2)$\n",
    "\n",
    "Wardrop equilibrium is $f^{(0)} = (1,0)$\n",
    "\n",
    "In this example, the optimal cost is $\\sum_e f_e^* d_e(f_e^*) = 0.75$. Notice that $d_1(f_1^*) = 1/2, d_2(f_2^*) = 1$\n",
    "\n",
    "The cost at Wardrop is $\\sum_e f_e^{(0)} d_e(f_e^{(0)}) = 1$. Notice that $d_1(f_1^*) = d_2(f_2^*) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to add tolls: marginal tolls\n",
    "We add tolls $\\omega \\in \\mathrm{R}^E_+$, such that users choose the path based on delay functions $d_e^{(\\omega_e)}(f_e) = d_e(f_e) + \\omega_e$. We would like to find optimal tolls $\\omega^*$ such that the Wardrop equilibrium with tolls is equal to the social optimum flow, i.e., $f^* = f^{(\\omega^*)}$, where\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\tf^{*} \\in \\ & \\underset{\\substack{f \\in \\mathrm{R}^{E}_+ \\\\ B f = \\nu}}{\\arg\\min}\n",
    "\t& & \\sum_{e \\in E} \\psi_e(f_e).\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\tf^{(\\omega^*)} \\in \\ & \\underset{\\substack{f \\in \\mathrm{R}^{E}_+ \\\\ B f = \\nu}}{\\arg\\min}\n",
    "\t& & \\sum_{e \\in E} \\int_{0}^{f_e} d_e^{(\\omega^*_e)} (s) ds.\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "**Theorem**: An optimal toll configuration is $\\omega^*_e = \\psi_e'(f_e^*) - d_e(f_e^*)$ for all links $e$. \n",
    "\n",
    "**Remark**: Those tolls are called marginal pricing tolls. However, optimal tolls do not have to be unique, there might exist other optimal tolls. For standard cost function $\\psi_e(f_e) = f_e d_e(f_e)$, marginal pricing tolls read $\\omega_e^* = f_e^* d_e'(f_e^*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear averaging dynamics\n",
    "In the first part of the lab we study linear averaging dynamics on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G=(V,E,W)$ be a weighted graph, and $x(t) \\in \\mathrm{R}^{V}$ denote the state of the nodes of the graph.\n",
    "\n",
    "The dynamics of $x(t)$ reads\n",
    "\n",
    "$$\n",
    "x(t+1) = Px(t),\n",
    "$$\n",
    "\n",
    "where $P$ is the normalized adjacency matrix.\n",
    "Among the applications, the most popular is opinion dynamics, where $x_i$ indicates the opinion of node $i$. This dynamics is known as French - De Groot.\n",
    "\n",
    "Note that we assume by convention that the opinion of node $i$ is influenced by the opinion of node $j$ if $P_{ij}>0$, i.e., the link $(i,j)$ has to be interpreted as $i$ watching $j$ and updating her opinion based on opinion of $j$.\n",
    "\n",
    "**Observation**: observe that $\\mathbf{1}$ is an equilibrium distribution, since $\\mathbf{1} = P \\mathbf{1}$ ($P$ is row-stochastic by construction), i.e., consensus distributions are equilibria of the dynamics.\n",
    "\n",
    "**Question**: what are the conditions under which the dynamics converges to consensus?\n",
    "\n",
    "**Theorem**: assume that\n",
    "- its condensation graph has 1 sink;\n",
    "- the sink component of the graph is aperiodic;\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1},\n",
    "$$\n",
    "\n",
    "i.e., the agents get to consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why aperiodicity matters: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = {0:[0,0], 1:[0,2], 2:[2,2], 3:[2,0]}\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the graph is periodic because of every cycle has even length (the graph is bipartite and undirected, thus its period is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary that maps the label of nodes  \n",
    "# (from (0,0) to (2,1)) to their index (from 0 to n_nodes-1)\n",
    "indices = dict()\n",
    "for i in range(n_nodes):\n",
    "    indices[list(G.nodes)[i]] = i\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign initial opinion to nodes and run the dynamics\n",
    "x = np.array([1,0,1,0])\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes with opinion 1 are red, nodes with opinion 0 are white.\n",
    "\n",
    "After one iteration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ x\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) \n",
    "\n",
    "print(\"x(1):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect after 5 iterations from the initial condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ P @ P @ P @ x\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) \n",
    "\n",
    "print(\"x(5):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periodicity of the graph does not allow a proper mixing of the opinions!\n",
    "\n",
    "Let us add a link to make the graph aperiodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "G.add_edge(0,2)\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run again the dynamics with same initial conditions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,0,0,1])\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(1):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(2):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(3):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(4):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(5):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(10):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(15):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(20):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(25):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(30):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics reachs consensus.\n",
    "\n",
    "### Two questions\n",
    "- How fast the consensus is achieved?\n",
    "- What is the consensus value?\n",
    "\n",
    "We will answer to these questions later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 1 sink in the condensation graph: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sink components does this graph have?\n",
    "\n",
    "Let us compute the condensation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condensation graph has 2 sinks. Thus, the sufficient conditions under which the dynamics converges to consensus does not hold.\n",
    "\n",
    "Let us figure out why by an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(100):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics does not reach consensus.\n",
    "\n",
    "**Question**: can you intuitively understand why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now add a link in such a way that the condensation graph has now a single sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(6,3)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now run the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(199):\n",
    "    x = P @ x\n",
    "print(\"x(200):\", x, \"\\n\")\n",
    "\n",
    "for n in range(999):\n",
    "    x = P @ x\n",
    "print(\"x(1000):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reach consensus!!\n",
    "\n",
    "## Consensus value\n",
    "\n",
    "How is the consensus value computed?\n",
    "\n",
    "Let $\\pi$ denote the normalized left dominant eigenvector of $P$, i.e., the normalized $\\pi$ such that $P' \\pi = \\pi$ (which is unique because the graph has one sink only).\n",
    "We use the fact that\n",
    "\n",
    "$$\n",
    "\\pi' x(t) = \\pi' P x(t-1) = \\pi' x(t-1),\n",
    "$$\n",
    "\n",
    "thus $\\pi' x(t)$ is constant along the dynamics. Thus,\n",
    "\n",
    "$$\n",
    "\\pi' x(0) = \\pi' \\lim_{t \\to + \\infty} x(t) = \\alpha \\pi' \\mathbf{1} = \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thie computation above says that the consensus value $\\alpha$ is the weighted average of the initial conditions of the nodes, where the weights are given by the (unique) invariant distribution $\\pi$.\n",
    "\n",
    "Recall that $\\pi$ solving $\\pi = P' \\pi$ is also the invariant distribution centrality, thus the more a node is central the more its initial opinion affects the consensus value.\n",
    "\n",
    "Let us explore the form of $\\pi$ for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(P.T)\n",
    "\n",
    "# selects the eigenvalue 1 and print the eigenvector\n",
    "for index in [i for i in range(len(G)) if np.isclose(w[i],1)]: \n",
    "    pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "    pi = pi/np.sum(pi)\n",
    "    print(\"pi\", index, \"=\", pi)\n",
    "    \n",
    "nx.draw(G,pos,with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The invariant distribution centrality is 0 for all the nodes that do not belong to the sink of the condensantion graph!\n",
    "\n",
    "This implies that the initial opinion of the nodes not belonging to the sink are negligible for the consensus value.\n",
    "\n",
    "The intuition for this is that the nodes 0, 1 and 2 do not care of the other nodes, because are not out-connected to any other node out of the component, and they reach consensus because the induced subgraph on 0,1,2 is aperiodic and strongly connected.\n",
    "Thus, their evolution is not affected by other nodes. Conversely, the other nodes update their opinion based on 2 also, thus eventually they tend to agree to the opinion of node 2 (and thus 0 and 1 as well).\n",
    "\n",
    "Let us modify the initial condition of nodes 3,4,5,6 to observe that the consensus value is not affected by this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial condition\n",
    "x = [1, 1, 0, 80, 25, 8, 12]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(200):\n",
    "    x = P @ x\n",
    "print(\"x(300):\", x, \"\\n\")\n",
    "\n",
    "for n in range(1000):\n",
    "    x = P @ x\n",
    "print(\"x(1300):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed of convergence\n",
    "\n",
    "Let us work now for undirected (the following argument holds only for undirected) connected graphs. If the graph is also aperiodic, the dynamics is guaranteed to converge to consensus.\n",
    "\n",
    "Let $\\lambda:=\\max \\{\\lambda_2,|\\lambda_n|\\}$, where $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_n$ are the eigenvalues of $P$. Recall that $\\lambda_n \\ge -1$ by construction of $P$. \n",
    "\n",
    "It is known that the dynamics reaches consensus exponentially fast. In particular, the distance from consensus at time $t$ is in some sense proportional to $\\lambda^t$ (this will be shown more formally in the theoretical lectures).\n",
    "\n",
    "Thus, if $\\lambda$ is close to $1$, then the convergence is slow, whereas if $\\lambda$ is small the convergence is faster.\n",
    "\n",
    "Note also that for periodic graphs, by Perron-Frobenius theorem have $\\lambda_n = -1$ (thus $\\lambda=1$), then the convergence to consensus is not achieved. This is coherent with the theory of consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: note that every periodic strongly connected graph can be made periodic by adding at least a selfloop in the graph. Indeed, if a selfloop $(i,i)$ is added, then the period of node $i$ is 1. Since all the nodes in the same connected component have same period, then all the nodes have period $1$ and the graph is aperiodic.\n",
    "\n",
    "To avoid periodic graphs, sometimes it is useful to introduce the **lazy dynamics** obtained by replacing $P$ with \n",
    "\n",
    "$$\n",
    "\\frac{P+\\mathbf{I}}{2}\n",
    "$$\n",
    "\n",
    "This is equivalent to adding selfloops to each node in the graph with weight equivalent to the degree of the node itself.\n",
    "\n",
    "An interpretation for the lazy dynamics is that nodes have some inertia in the opinion. Instead of averaging over the opinions of the neighbors, they also take into account their opinion at the previous step. In fact,\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\frac{x_i(t) + \\sum_{j} P_{ij} x_j(t)}{2}.\n",
    "$$\n",
    "\n",
    "Let us go back to the initial periodic example, and show that the lazy dynamics converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = P/2 + np.diag(np.ones(4))/2\n",
    "\n",
    "x = np.array([1, 0, 1, 0])\n",
    "\n",
    "for n in range(9):\n",
    "    x = P @ x\n",
    "print(\"x(10):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How fast is the convergence of lazy dynamics?\n",
    "\n",
    "Note that $\\lambda_n(P_{lazy}) = 1/2 + \\lambda_n(P)/2 \\ge 1/2 + (-1/2) = 0$.\n",
    "\n",
    "Thus, $\\lambda = \\lambda_2$. \n",
    "\n",
    "In the lazy dynamics, the speed convergence is governed by $\\lambda_2$. Let us now define the relaxation time as\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{1}{1-\\lambda_2}\n",
    "$$\n",
    "\n",
    "For undirected graphs, $\\lambda_2$ may be related to the level of connectedness of the graph. In particular, if the graph is well connected, $\\lambda_2$ is smaller and the convergence to consensus is faster.\n",
    "\n",
    "We do not investigate the details on how to define \"connectedness\" of graphs in proper way here. However, we can verify by a simple example how connectedness of the graph influences the speed of convergence.\n",
    "\n",
    "Let us consider a **cycle graph** with 1000 nodes.\n",
    "\n",
    "For the cycle graph one can show that\n",
    "\n",
    "$$\n",
    "\\lambda_2(P) = \\cos \\left(\\frac{2\\pi (n-1)}{n}\\right).\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to + \\infty} \\lambda(P_{lazy}) = \\frac{1}{2} + \\lim_{n \\to + \\infty} \\frac{1}{2} \\cos \\frac{2\\pi}{n} = 1-\\frac{\\pi}{n},\n",
    "$$\n",
    "\n",
    "and the relaxation time for the cycle is\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{n}{\\pi}.\n",
    "$$\n",
    "\n",
    "This means that the convergence is achieved exponentially with a rate that scales linearly with $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "P = P = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the complete graph, which is the most connected graph by definition. For the complete graph,\n",
    "\n",
    "$$\n",
    "W=\\mathbf{1}\\mathbf{1}'-I.\n",
    "$$\n",
    "\n",
    "Since $\\mathbf{1}\\mathbf{1}'$ has equal columns, it has rank $1$. Thus $\\mathbf{1}\\mathbf{1}'$ has $n-1$ eigenvalues equal to $0$. The remaining eigenvalue can be found by using the fact that the sum of the eigenvalues is the trace of the matrix. Since $=\\mathbf{1}\\mathbf{1}'-I$, the spectrum of $W$ is\n",
    "\n",
    "$$\n",
    "\\sigma_W = \\{n-1,-1,\\cdots,-1\\}\n",
    "$$\n",
    "\n",
    "Since the complete graph is regular and every node has degree $n-1$, $P=W/(n-1)$\n",
    "Thus, the spectrum of $P$ is\n",
    "\n",
    "$$\n",
    "\\sigma_P = \\{1,-\\frac{1}{n-1},\\cdots,-\\frac{1}{n-1}\\},\n",
    "$$\n",
    "\n",
    "and $P_{lazy}$ has spectrum\n",
    "\n",
    "$$\n",
    "\\sigma_{P_{lazy}} = \\{1,-\\frac{1}{2(n-1)}+\\frac{1}{2},\\cdots,-\\frac{1}{2(n-1)}+\\frac{1}{2}\\}\n",
    "$$\n",
    "\n",
    "This implies that $\\lambda_2 = \\frac{1}{2}-\\frac{1}{2(n-1)} = \\frac{n-2}{2(n-1)}$ and the relaxation time for large $n$ in the complete graph tends\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to +\\infty} \\tau_{rel} = 2,\n",
    "$$\n",
    "\n",
    "i.e., even for infinite $n$ the relaxation time is finite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "P = P = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "n=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = P @ x\n",
    "    n=n+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisdom of crowds\n",
    "Consider a graph, and assume that state of each node represents a noisy estimate of the real state $\\mu$, i.e.,\n",
    "\n",
    "$$\n",
    "x_i = \\mu + y_i,\n",
    "$$\n",
    "\n",
    "with $E[y_i]=0$, and the variance $\\sigma^2 (y_i) = \\sigma^2$ for each $i$.\n",
    "\n",
    "Assume that the graph is connected and aperiodic Eventually, the agents will reach consensus, i.e., $\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1}$. \n",
    "\n",
    "**Question**: what is the consensus value $\\alpha$?\n",
    "\n",
    "Notice that $\\alpha = \\pi' (\\mu \\mathbf{1} + y) = \\mu + \\pi'y$, then\n",
    "\n",
    "$$\n",
    "E[\\alpha] = \\mu + \\pi' E[y] = \\mu\n",
    "$$\n",
    "\n",
    "so the final estimate of the network is unbiased. Moreover,\n",
    "\n",
    "$$\n",
    "\\quad \\sigma_{\\alpha}^2 = \\sigma^2 \\sum_{i} \\pi_i^2 < \\sigma^2,\n",
    "$$\n",
    "\n",
    "because $\\sum_{i} \\pi_i^2 <1$ unless the graph has a unique sink node. The interesting observation is that the estimate $\\alpha$ has a smaller variance than $\\sigma$, i.e., the crowd is able to reconstruct a more precise estimate of the real state than the single agents of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify this on a complete graph, where $\\pi_i = 1/n$, thus $\\sigma_\\alpha^2 = \\sigma^2/n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(100)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# start with random initial states and run the dynamics 200 times\n",
    "# store in alfa_err the consensus values at each run\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns random values in [0,1], thus \\mu = 1/2\n",
    "    x = np.random.rand(100)\n",
    "    var = np.var(x)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Variance of the node states:\", 1/12)\n",
    "print(\"Variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the variance of $\\alpha$ is about $1/100$ of the original variance.\n",
    "\n",
    "Note that $\\sum_{i} \\pi_i^2$ tends to 1 if one node has almost all the centrality, and is minimal when the nodes have the same centrality (as in the complete graph, or in the cycle graph). This implies that if a graph is more 'democratic', then the consensus algorithm leads to better estimates of the true state. If a few nodes have all the centralities, the consensus value is less reliable.\n",
    "\n",
    "Let us see this with a another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# start with random initial states and run the dynamics\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns random values in [0,1], thus \\mu = 1/2\n",
    "    x = np.random.rand(10)\n",
    "    var = np.var(x)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Expected variance of the node states:\", 1/12)\n",
    "print(\"Empirical variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph the consensus value is exactly the initial state of node $0$, because the condensantion graph has 1 sink only, which is node $0$.\n",
    "\n",
    "$$\n",
    "\\pi = \\delta^{(0)}.\n",
    "$$\n",
    "\n",
    "This graph is the opposite of the complete graph, in the sense that all the invariant distribution centrality is totally on node $0$. Thus the variance of the consensus state equals the variance of the single node.\n",
    "\n",
    "Note that this argument holds independently of the size of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: distributed computation of average\n",
    "\n",
    "Let the node set describe a set of sensors that are deployed in some region in order to collect measurements of some quantity of interest (for example, the temperature). \n",
    "\n",
    "Assume that these sensors have limited communication and computation capabilities that allow each of them to exchange information only with those other sensors that are close enough in space. \n",
    "\n",
    "Let the graph $G = (V, E)$ describe the pattern of closeness among the sensors $i$ and $j$ so that there is an undirected link between node $i$ and node $j$ if they can communicate to each other (possibly using link weights decreasing with distance). Then, one can design a distributed algorithm for computing the average of the sensor's measurements based on the averaging dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i(0)$ be the measurement of each node. \n",
    "\n",
    "We are interested in designing an iterative distributed algorithm that allows the nodes to compute\n",
    "\n",
    "$$\n",
    "x = \\frac{1}{n}\\sum_i x_i(0)\n",
    "$$\n",
    "\n",
    "**First attempt**: we run a consensus algorithm. Since the graph is undirected, $\\pi_i = \\frac{w_i}{\\sum_j w_j}$. Thus, the algorithm converges to a consensus $\\alpha \\mathbf{1}$ such that\n",
    "\n",
    "$$\n",
    "\\alpha = \\sum_{i} \\frac{w_i}{w} x_i(0).\n",
    "$$\n",
    "\n",
    "If each edge knows its degree $w_i$, each node can rescale its initial state, i.e., $y_i(0) = \\frac{x_i(0)}{w_i}$. The consensus algorithm for the variable $y_i$ thus converges to\n",
    "\n",
    "$$\n",
    "\\alpha_y = \\sum_{i} \\frac{w_i}{w} y_i(0) = \\frac{1}{w} \\sum_{i} x_i(0).\n",
    "$$\n",
    "\n",
    "If we assume that each node knows the average degree of the network, thus\n",
    "\n",
    "$$\n",
    "x = \\alpha_y \\frac{w}{n} = \\alpha_y \\overline{w}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "n_nodes = len(G)\n",
    "\n",
    "x = np.random.rand(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us run the consensus algorithm for y\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "y = x/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    y = P @ y\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus on y\n",
    "print(\"average computed distributively\", y[0] * np.sum(degrees) / n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works! Unfortunately, requiring that each node knows the average degree of the network is not realistic.\n",
    "\n",
    "However, there exists another way to solve the problem.\n",
    "\n",
    "**Second attempt**: we run a second averaging dynamics, with initial condition $z_i(0) = \\frac{1}{w_i}$.\n",
    "\n",
    "This converges to\n",
    "\n",
    "$$\n",
    "\\alpha_z = \\lim_{t \\to + \\infty} z_i(t) = \\sum_i z_i(0) \\frac{w_i}{w} = \\sum_{i} \\frac{1}{w} = \\frac{1}{\\overline{w}}\n",
    "$$\n",
    "\n",
    "By combining the two, each node can estimate the average estimate by \n",
    "\n",
    "$$\n",
    "\\frac{\\lim_{t \\to + \\infty} y_i(t)}{\\lim_{t \\to + \\infty} z_i(t)} = \\frac{\\alpha_y}{\\alpha_z} = \\frac{x}{\\overline{w}} \\cdot \\overline{w} = x.\n",
    "$$\n",
    "\n",
    "This method does not require any global knowledge on the network and it is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us implement this\n",
    "\n",
    "z = 1/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    z = P @ z\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus both on y and z\n",
    "print(\"average computed distributively\", y[0] / z[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
